<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="text/html; charset=UTF-8" http-equiv="content-type"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<meta name="robots" content="index, follow">
<!-- <script> -->
<!-- MathJax = { -->
<!--   tex: { -->
<!--     inlineMath: [['$', '$'], ['\\(', '\\)']] -->
<!--   } -->
<!-- }; -->
<!-- </script> -->
<!-- <script type="text/javascript" id="MathJax-script" async -->
<!--   src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> -->
<!-- </script> -->
<link rel="stylesheet" href="https://denehoffman.com/katex.css">
<script defer src="https://denehoffman.com/katex.js"></script>
<script defer src="https://denehoffman.com/auto-render.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ]
        });
    });
</script>













<title>The BFGS Algorithm Family in Rust (Part 1)</title>



<meta name="title" content="The BFGS Algorithm Family in Rust (Part 1)">


<meta name="author" content="Nathaniel D. Hoffman">


<meta property="og:type" content="website">
<meta property="og:url" content="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/">

<meta property="og:site_name" content="">


<meta property="og:title" content="The BFGS Algorithm Family in Rust (Part 1)">





<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/">

<meta property="twitter:title" content="The BFGS Algorithm Family in Rust (Part 1)">




<link rel="canonical" href="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/">




<link rel="stylesheet" type="text/css" href="https://speyll.github.io/suCSS/reset-min.css"/>
<link rel="stylesheet" type="text/css" href="https://speyll.github.io/suCSS/suCSS-min.css"/>
<link rel="stylesheet" type="text/css" href="https://denehoffman.com/css/style.css"/>

<script src="https://denehoffman.com/js/script.js" defer></script>


</head>
<body>
      <header>
          

  


  <nav id="nav-bar">
    
      <a href="&#x2F;" class="">
        
        &lt;home&gt;
      </a>
    
      <a href="&#x2F;blog" class="">
        
        &lt;blog&gt;
      </a>
    
      <a href="&#x2F;publications" class="">
        
        &lt;publications&gt;
      </a>
    
      <a href="&#x2F;cv" class="">
        
        &lt;cv&gt;
      </a>
    
      <a href="&#x2F;projects" class="">
        
        &lt;projects&gt;
      </a>
    
    <div>
      <input type="checkbox" id="theme-toggle" style="display: none;">
      <label for="theme-toggle" id="theme-toggle-label"><svg id="theme-icon" class="icons"><use href="https://denehoffman.com/icons.svg#lightMode"></use></svg></label>
      <audio id="theme-sound">
        <source src="https://denehoffman.com/click.ogg" type="audio/ogg">
      </audio>
    </div>
  </nav>


      </header>
      <main>
          
<div><a href="..">..</a>/<span class="accent-data">the-bfgs-algorithm-family-in-rust-part-1</span></div>
<time datetime="2024-09-08">Published on: <span class="accent-data">2024-09-08</span></time>

<h1>The BFGS Algorithm Family in Rust (Part 1)</h1>



<p>The BFGS (Broyden-Fletcher-Goldfarb-Shanno) algorithm and its derivatives were (and for the most part still are) the gold standard methods for quasi-Newton optimization. In this post, I want to give a brief overview of the main idea, the limited-memory adaptation (L-BFGS), and the bounded version (L-BFGS-B) and how I implemented them in a Rust crate I'm developing called <a href="https://github.com/denehoffman/ganesh"><code>ganesh</code></a>. The full algorithm can be seen there, and I will mainly be focusing on the main methodology, since the actual literature on it is rather old and difficult to parse (and even has a few typos!).</p>
<p>That being said, I wouldn't have done it without the following articles/projects which have guided my understanding:</p>
<ul>
<li><a href="https://doi.org/10.1007/978-0-387-40065-5">"Numerical Optimization"</a> by Jorge Nocedal and Stephen J. Wright</li>
<li><a href="https://aria42.com/blog/2014/12/understanding-lbfgs">"Numerical Optimization: Understanding L-BFGS"</a> by <a href="https://aria42.com/">Aria Haghighi</a></li>
<li><a href="https://github.com/avieira/python_lbfgsb/">L-BFGS-B in pure Python</a> by <a href="https://github.com/avieira">@avieira (Alex Vieira?)</a></li>
<li><a href="https://github.com/bgranzow/L-BFGS-B">L-BFGS-B in pure MATLAB</a> by <a href="https://github.com/bgranzow">Brian Granzow</a></li>
<li><a href="https://doi.org/10.1137/0916069">"A Limited Memory Algorithm for Bound Constrained Optimization"</a> by Richard H. Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu</li>
</ul>
<h1 id="quasi-newton">Quasi-Newton?</h1>
<p>Typically, in numeric optimization problems, we want to define some stepping process that will cause us to approach a minimum or maximum as quickly as possible. For our purposes, we'll just assume we only care about minimizing, and we'll also assume that there <em>is</em> a single global minimum to the function in question, or at least that we don't care about falling into a deep local minimum. The simplest non-trivial way to do this is by gradient descent:
$$
\vec{x}_{k+1} = \vec{x}_k - \alpha_k \vec{\nabla} f(\vec{x}_k)
$$
where $f: \mathbb{R}^n \to \mathbb{R}$ is the objective function we are trying to minimize and $\alpha_n$ is some positive step length (also called the learning rate). The minus sign here is why we call it gradient descent; we are always moving opposite the gradient, which always points uphill. For simplicity, we'll also refer to the gradient as a function $\vec{g}(\vec{x}) \equiv \vec{\nabla}f(\vec{x})$ Now if you just throw in some very small value for $\alpha$ and cross your fingers, you might eventually end up at the function's minimum, but it certainly won't be the most efficient way to get there. If your $\alpha$ is too big, you could end up overshooting the minimum and bouncing back and forth around it endlessly.</p>
<p>There are several ways we can optimize the choice of step length. Skip ahead to <a href="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/#line-searches">here</a> to see the implementation I use for the BFGS family.</p>
<h1 id="rust-implementation">Rust implementation</h1>
<h2 id="function-trait">Function trait</h2>
<p>Let's start by defining a trait which will evaluate our function $f$ and its gradient $\vec{g}$. I want the input parameter values $\vec{x}$ to be generic so that both <code>f64</code> and <code>f32</code> types can be used, as well as any other struct with the right trait implementations. I also want these functions to return <code>Result</code>s with a generic error type <code>E</code> so that users can handle any errors their own functions create. Finally, we should consider adding optional arguments to these functions. Again, we will turn to generics, but allow users to pass a <code>&amp;mut U</code> called <code>user_data</code>. This term is mutable because it will give us the most flexibility later on. The trait for a function might look something like this:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">use </span><span>num::{traits::NumAssign, Float, FromPrimitive};
</span><span>
</span><span style="color:#b48ead;">pub trait </span><span>Function&lt;T, U, E&gt;
</span><span>where
</span><span>    T: Float + FromPrimitive + Debug + NumAssign,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">evaluate</span><span>(&amp;</span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">x</span><span>: &amp;[T], </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U) -&gt; Result&lt;T, E&gt;;
</span><span> 
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">gradient</span><span>(&amp;</span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">x</span><span>: &amp;[T], </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U) -&gt; Result&lt;Vec&lt;T&gt;, E&gt; {
</span><span>        </span><span style="color:#b48ead;">let</span><span> n = x.</span><span style="color:#96b5b4;">len</span><span>();
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> grad = vec![T::zero(); n];
</span><span>        </span><span style="color:#b48ead;">let</span><span> h: Vec&lt;T&gt; = x
</span><span>            .</span><span style="color:#96b5b4;">iter</span><span>()
</span><span>            .</span><span style="color:#96b5b4;">map</span><span>(|&amp;</span><span style="color:#bf616a;">xi</span><span>| T::cbrt(T::epsilon()) * (</span><span style="color:#b48ead;">if</span><span> xi == T::zero() { T::one() } </span><span style="color:#b48ead;">else </span><span>{ xi }))
</span><span>            .</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>        </span><span style="color:#b48ead;">for</span><span> i in </span><span style="color:#d08770;">0</span><span>..n {
</span><span>            </span><span style="color:#b48ead;">let mut</span><span> x_plus = x.</span><span style="color:#96b5b4;">to_vec</span><span>();
</span><span>            </span><span style="color:#b48ead;">let mut</span><span> x_minus = x.</span><span style="color:#96b5b4;">to_vec</span><span>();
</span><span>            x_plus[i] += h[i];
</span><span>            x_minus[i] -= h[i];
</span><span>            </span><span style="color:#b48ead;">let</span><span> f_plus = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">evaluate</span><span>(&amp;x_plus, user_data)?;
</span><span>            </span><span style="color:#b48ead;">let</span><span> f_minus = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">evaluate</span><span>(&amp;x_minus, user_data)?;
</span><span>            grad[i] = (f_plus - f_minus) / (convert!(</span><span style="color:#d08770;">2.0</span><span>, T) * h[i]);
</span><span>        }
</span><span>        Ok(grad)
</span><span>    }
</span><span>}
</span></code></pre>
<p>I also use a little macro to convert raw numeric fields to our generic type <code>T</code>, if possible:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span>#[</span><span style="color:#bf616a;">macro_export</span><span>]
</span><span style="color:#96b5b4;">macro_rules! </span><span>convert {
</span><span>    (</span><span style="color:#bf616a;">$value</span><span>:</span><span style="color:#b48ead;">expr</span><span>, </span><span style="color:#bf616a;">$type</span><span>:</span><span style="color:#b48ead;">ty</span><span>) =&gt; {{
</span><span>        #[</span><span style="color:#bf616a;">allow</span><span>(clippy::unwrap_used)]
</span><span>        &lt;</span><span style="color:#bf616a;">$type </span><span>as num::NumCast&gt;::from(</span><span style="color:#bf616a;">$value</span><span>).</span><span style="color:#96b5b4;">unwrap</span><span>()
</span><span>    }};
</span><span>}
</span></code></pre>
<p>Let's walk through the anatomy of the trait above. I think the <code>evaluate</code> method is pretty self-explanatory (given that it's an empty template), but the gradient method is a bit more complex. First of all, I'm implementing a central finite-difference here:
$$
\frac{\partial f(\vec{x})}{\partial x_i} = \frac{f(\vec{x} + h_i \hat{e}_i) - f(\vec{x} - h_i \hat{e}_i)}{2h_i}
$$
The tricky detail is choosing a value for $h_i$. In practice, machine epsilon is too small! What we actually should use is $h_i = \sqrt[3]{\varepsilon} x_i $ when $x_i \neq 0$ and $h_i = \sqrt[3]{\varepsilon}$ in the event that $x_i = 0$.</p>
<h2 id="algorithm-trait">Algorithm Trait</h2>
<p>Next, since we want to implement three algorithms with very similar features, it might make sense to create a generic trait that can be used by some executor that will wrap all of these methods into a nice API. All of these algorithms will will need to know the following:</p>
<ol>
<li>The objective <code>Function</code></li>
<li>The starting point $x_0$</li>
<li>Any bounds on the free parameters (we will ignore bounds for the BFGS and L-BFGS methods here, although an experimental change of variables is implemented in the final crate)</li>
<li>The <code>user_data</code> to pass to the <code>Function</code></li>
</ol>
<p>We should also define what an algorithm should give us in return!</p>
<ol>
<li>The best position at the end of the minimization, $x_\text{best}$</li>
<li>The function value at that point, $f(x_\text{best})$</li>
<li>The number of function/gradient evaluations</li>
<li>Some indication as to whether the result of the minimization is valid</li>
<li>Some <code>String</code> message that can tell us any additional information about how the fit progressed/is progressing</li>
</ol>
<p>Let's call this struct <code>Status</code> and define it as follows:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span>#[</span><span style="color:#bf616a;">derive</span><span>(Debug, Default, Clone)]
</span><span style="color:#b48ead;">pub struct </span><span>Status&lt;T&gt; {
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">message</span><span>: String,
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">x</span><span>: Vec&lt;T&gt;,
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">fx</span><span>: T,
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">n_f_evals</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">n_g_evals</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">converged</span><span>: </span><span style="color:#b48ead;">bool</span><span>,
</span><span>}
</span><span style="color:#b48ead;">impl</span><span>&lt;T&gt; Status&lt;T&gt; {
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">update_message</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">message</span><span>: &amp;</span><span style="color:#b48ead;">str</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.message = message.</span><span style="color:#96b5b4;">to_string</span><span>();
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">update_position</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">pos</span><span>: (</span><span style="color:#bf616a;">Vec</span><span>&lt;</span><span style="color:#bf616a;">T</span><span>&gt;, </span><span style="color:#bf616a;">T</span><span>)) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.x = pos.</span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#bf616a;">self</span><span>.fx = pos.</span><span style="color:#d08770;">1</span><span>;
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">set_converged</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.converged = </span><span style="color:#d08770;">true</span><span>;
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">inc_n_f_evals</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.n_f_evals += </span><span style="color:#d08770;">1</span><span>;
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">inc_n_g_evals</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.n_g_evals += </span><span style="color:#d08770;">1</span><span>;
</span><span>    }
</span><span>}
</span><span style="color:#b48ead;">impl</span><span>&lt;T&gt; Display </span><span style="color:#b48ead;">for </span><span>Status&lt;T&gt;
</span><span style="color:#b48ead;">where
</span><span>    T: Debug + Display,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">fmt</span><span>(&amp;</span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">f</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>std::fmt::Formatter&lt;&#39;_&gt;) -&gt; std::fmt::Result {
</span><span>        writeln!(f, &quot;</span><span style="color:#a3be8c;">MSG:       </span><span style="color:#d08770;">{}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.message)?;
</span><span>        writeln!(f, &quot;</span><span style="color:#a3be8c;">X:         </span><span style="color:#d08770;">{:?}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.x)?;
</span><span>        writeln!(f, &quot;</span><span style="color:#a3be8c;">F(X):      </span><span style="color:#d08770;">{}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.fx)?;
</span><span>        writeln!(f, &quot;</span><span style="color:#a3be8c;">N_F_EVALS: </span><span style="color:#d08770;">{}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.n_f_evals)?;
</span><span>        writeln!(f, &quot;</span><span style="color:#a3be8c;">N_G_EVALS: </span><span style="color:#d08770;">{}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.n_g_evals)?;
</span><span>        write!(f, &quot;</span><span style="color:#a3be8c;">CONVERGED: </span><span style="color:#d08770;">{}</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.converged)
</span><span>    }
</span><span>}
</span></code></pre>
<p>Note that we have set this up in a way that doesn't let any algorithm decrement the number of function/gradient evaluations. Additionally, no outside function can un-converge a converged <code>Status</code>. We will also typically update $f(x_\text{best})$ every time we update $x_\text{best}$, so there's only one way to do this to ensure they don't get out of sync for any reason.</p>
<p>Next, the <code>Algorithm</code> trait itself:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub trait </span><span>Algorithm&lt;T, U, E&gt; {
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">initialize</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">x0</span><span>: &amp;[T],
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>    ) -&gt; Result&lt;(), E&gt;;
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">step</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">i_step</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>    ) -&gt; Result&lt;(), E&gt;;
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">check_for_termination</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>    ) -&gt; Result&lt;</span><span style="color:#b48ead;">bool</span><span>, E&gt;;
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">get_status</span><span>(&amp;</span><span style="color:#bf616a;">self</span><span>) -&gt; &amp;Status&lt;T&gt;;
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">postprocessing</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>    ) -&gt; Result&lt;(), E&gt; {
</span><span>        Ok(())
</span><span>    }
</span><span>}
</span></code></pre>
<p>Most of these methods are fairly self-explanatory and have very similar signatures. Finally, let's wrap all of this up in a nice interface for the end-user to work with:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub struct </span><span>Minimizer&lt;T, U, E, A&gt;
</span><span>where
</span><span>    A: Algorithm&lt;T, U, E&gt;,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">pub </span><span style="color:#bf616a;">status</span><span>: Status&lt;T&gt;,
</span><span>    </span><span style="color:#bf616a;">algorithm</span><span>: A,
</span><span>    </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>    </span><span style="color:#bf616a;">max_steps</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#bf616a;">dimension</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#bf616a;">_user_data</span><span>: PhantomData&lt;U&gt;,
</span><span>    </span><span style="color:#bf616a;">_error</span><span>: PhantomData&lt;E&gt;,
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl</span><span>&lt;T, U, E, A: Algorithm&lt;T, U, E&gt;&gt; Minimizer&lt;T, U, E, A&gt;
</span><span style="color:#b48ead;">where
</span><span>    T: Float + FromPrimitive + Debug + Display + Default,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">const </span><span style="color:#d08770;">DEFAULT_MAX_STEPS</span><span>: </span><span style="color:#b48ead;">usize </span><span>= </span><span style="color:#d08770;">4000</span><span>;
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">new</span><span>(</span><span style="color:#bf616a;">algorithm</span><span>: A, </span><span style="color:#bf616a;">dimension</span><span>: </span><span style="color:#b48ead;">usize</span><span>) -&gt; </span><span style="color:#b48ead;">Self </span><span>{
</span><span>        </span><span style="color:#b48ead;">Self </span><span>{
</span><span>            status: Status::default(),
</span><span>            algorithm,
</span><span>            bounds: None,
</span><span>            max_steps: </span><span style="color:#b48ead;">Self</span><span>::</span><span style="color:#d08770;">DEFAULT_MAX_STEPS</span><span>,
</span><span>            dimension,
</span><span>            _user_data: PhantomData,
</span><span>            _error: PhantomData,
</span><span>        }
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">with_algorithm</span><span>(</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">algorithm</span><span>: A) -&gt; </span><span style="color:#b48ead;">Self </span><span>{
</span><span>        </span><span style="color:#bf616a;">self</span><span>.algorithm = algorithm;
</span><span>        </span><span style="color:#bf616a;">self
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub const fn </span><span style="color:#8fa1b3;">with_max_steps</span><span>(</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">max_steps</span><span>: </span><span style="color:#b48ead;">usize</span><span>) -&gt; </span><span style="color:#b48ead;">Self </span><span>{
</span><span>        </span><span style="color:#bf616a;">self</span><span>.max_steps = max_steps;
</span><span>        </span><span style="color:#bf616a;">self
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">minimize</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">x0</span><span>: &amp;[T],
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>    ) -&gt; Result&lt;(), E&gt; {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.algorithm
</span><span>            .</span><span style="color:#96b5b4;">initialize</span><span>(func, x0, </span><span style="color:#bf616a;">self</span><span>.bounds.</span><span style="color:#96b5b4;">as_ref</span><span>(), user_data)?;
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> current_step = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#b48ead;">while</span><span> current_step &lt;= </span><span style="color:#bf616a;">self</span><span>.max_steps
</span><span>            &amp;&amp; !</span><span style="color:#bf616a;">self
</span><span>                .algorithm
</span><span>                .</span><span style="color:#96b5b4;">check_for_termination</span><span>(func, </span><span style="color:#bf616a;">self</span><span>.bounds.</span><span style="color:#96b5b4;">as_ref</span><span>(), user_data)?
</span><span>        {
</span><span>            </span><span style="color:#bf616a;">self</span><span>.algorithm
</span><span>                .</span><span style="color:#96b5b4;">step</span><span>(current_step, func, </span><span style="color:#bf616a;">self</span><span>.bounds.</span><span style="color:#96b5b4;">as_ref</span><span>(), user_data)?;
</span><span>            current_step += </span><span style="color:#d08770;">1</span><span>;
</span><span>        }
</span><span>        </span><span style="color:#bf616a;">self</span><span>.algorithm
</span><span>            .</span><span style="color:#96b5b4;">postprocessing</span><span>(func, </span><span style="color:#bf616a;">self</span><span>.bounds.</span><span style="color:#96b5b4;">as_ref</span><span>(), user_data)?;
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> status = </span><span style="color:#bf616a;">self</span><span>.algorithm.</span><span style="color:#96b5b4;">get_status</span><span>().</span><span style="color:#96b5b4;">clone</span><span>();
</span><span>        </span><span style="color:#b48ead;">if</span><span> current_step &gt; </span><span style="color:#bf616a;">self</span><span>.max_steps &amp;&amp; !status.converged {
</span><span>            status.</span><span style="color:#96b5b4;">update_message</span><span>(&quot;</span><span style="color:#a3be8c;">MAX EVALS</span><span>&quot;);
</span><span>        }
</span><span>        </span><span style="color:#bf616a;">self</span><span>.status = status;
</span><span>        Ok(())
</span><span>    }
</span><span>}
</span></code></pre>
<p>For now, we will ignore the <code>Bound</code> struct mentioned here, since we won't use it till we get to the <code>L-BFGS-B</code> algorithm. Note that <code>PhantomData</code> is required here because we don't actually store anything of type <code>U</code> or <code>E</code> but we need to include it in generics.</p>
<p>The main <code>minimize</code> function should also look pretty straightforward. We first call <code>Algorithm::initialize</code> and then proceed into a while-loop that checks if we either exceed the maximum allowed algorithm steps or if <code>Algorithm::check_for_termination</code> tells us to stop the algorithm (in case of problems or convergence). Inside this loop, we just run <code>Algorithm::step</code>. We finish off with <code>Algorithm::postprocessing</code> and grab the final <code>Status</code> of the algorithm. This will be the workflow for every <code>Algorithm</code> we implement<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<h1 id="line-searches">Line Searches</h1>
<p>We will be implementing an algorithm that attempts to satisfy the Strong Wolfe conditions. These are conditions for accepting a step length given some step direction $\vec{p}$ (we'll see later why we need to generalize this, but for now you can always just imagine $\vec{p} = -g(\vec{x})$).</p>
<p>The first of these conditions is also called the Armijo rule:
$$
f(\vec{x} + \alpha_k \vec{p}) \leq f(\vec{x}) + c_1 \alpha_k \left(\vec{p} \cdot \vec{g}(\vec{x})\right)
$$
for some value $0 &lt; c_1 &lt; 1$. The usual choice of $c_1$ is $10^{-4}$, which I believe just comes from some experimentation on standard test functions. This method is also called the sufficient decrease condition, and we can see why. The left-hand side is the function value at the new location, which we hope is at least smaller than the previous location (otherwise we are ascending!). However, for it to be sufficiently smaller, the difference must exceed the final term in the equation, which is usually going to be negative due to that dot product.</p>
<p>The second condition, dubbed the curvature condition, requires that the gradient of the function decrease sufficiently. This is usually harder to accomplish, so when we implement this in Rust, we will make it optional but desired.
$$
-\left(\vec{p} \cdot \vec{g}(\vec{x} + \alpha_k \vec{p})\right) \leq -c_2 \left(\vec{p} \cdot \vec{g}(\vec{x})\right)
$$
This condition adds another hyperparameter, $0 &lt; c_1 &lt; c_2 &lt; 1$ where $c_2 = 0.9$ in most applications. However, if we really want to find the best point, we should try to satisfy the <strong>strong</strong> version of the curvature condition:
$$
\left|\vec{p}_k \cdot \vec{g}(\vec{x}_k + \alpha_k \vec{p}_k)\right| \leq c_2 \left|\vec{p}_k \cdot \vec{g}(\vec{x}_k)\right|
$$</p>
<p>We'll start the implementation with another trait (since other algorithms might use a different search method):</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub trait </span><span>LineSearch&lt;T, U, E&gt; {
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">search</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">x</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">p</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">max_step</span><span>: Option&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>        </span><span style="color:#bf616a;">status</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Status&lt;T&gt;,
</span><span>    ) -&gt; Result&lt;(</span><span style="color:#b48ead;">bool</span><span>, T, T, Vec&lt;T&gt;), E&gt;;
</span><span>}
</span></code></pre>
<p>We'll be implementing Algorithms 3.5 and 3.6 from <a href="https://doi.org/10.1007/978-0-387-40065-5">"Numerical Optimization"</a>, which (roughly) reads as follows:</p>
<h4 id="algorithm-3-5">Algorithm 3.5</h4>
<ol>
<li>$\alpha_0 \gets 0$, $\alpha_\text{max} &gt; 0$, $\alpha_1 \in (0, \alpha_\text{max})$, $i \gets 1$</li>
<li><code>loop</code>
<ol>
<li>
<p><code>if</code></p>
<p>$f(\vec{x} + \alpha_i \vec{p}) &gt; f(\vec{x}) + c_1\alpha_i\left(\vec{p}\cdot\vec{g}(\vec{x})\right)$ (not Armijo)</p>
<p><code>or</code></p>
<p>($i &gt; 1$ <code>and</code> $f(\vec{x} + \alpha_i \vec{p}) \geq f(\vec{x} + \alpha_{i-1}\vec{p})$) (the function value has not decreased since the previous step)</p>
<p><code>then</code> <code>return</code> $\text{zoom}(\alpha_{i-1}, \alpha_i)$</p>
</li>
<li>
<p><code>if</code></p>
<p>$\left|\vec{p}\cdot\vec{g}(\vec{x} + \alpha_i\vec{p})\right| &lt; c_2 \left|\vec{p}\cdot\vec{g}(\vec{x})\right|$ (strong Wolfe)</p>
<p><code>then</code> <code>return</code> $\alpha_i$</p>
</li>
<li>
<p><code>if</code></p>
<p>$\vec{p}\cdot\vec{g}(\vec{x} + \alpha_i\vec{p}) \geq 0$ (gradient at new position generally points in the same direction as the given step direction)</p>
<p><code>then</code> <code>return</code> $\text{zoom}(\alpha_i,\alpha_{i-1})$</p>
</li>
<li>
<p>$\alpha_{i+1} \in (\alpha_i, \alpha_\text{max})$ (choose some larger step that is smaller than the max step)</p>
</li>
<li>
<p>$i \gets i + 1$</p>
</li>
</ol>
</li>
</ol>
<p>In each loop, we are first checking to see if the function is sufficiently decreasing. If it isn't, we know that the step size overshoots. Imagine we are just minimizing into a 1D parabola. If we are sitting to the left of the minimum, the optimal step length $\alpha_\text{opt}$ would put us right at the minimum. If we pick a step $\alpha &lt; \alpha_\text{opt}$ would be fine, but it would mean we converge slower than optimal. The same can be said for a step length $\alpha &gt; \alpha_\text{opt}$, but at a certain point, we will be stepping to a point higher up the parabola than where we began, even though we are moving in the right direction! Step 2.1 ensures that if this happens, we will do a more refined search (<code>zoom</code>) between the current and previous step lengths (note that $\alpha_{i-1} = 0$ when $i=1$ on the first loop). This will happen a lot if we pick a starting step length that is too large (see the following diagram).</p>
<p><img src="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/line_search_increase.svg" alt="Taking a step that is too large" />
If we are decreasing, we are in that region where we are converging, but we might not be converging at an optimal rate. This is where the strong Wolfe condition comes in. We first project the gradients at the original and stepped positions onto the step direction. If the gradient <em>is</em> the step direction (well, opposite to it), then we can ignore $\vec{p}$ here and think of this in terms of a change in gradient magnitude. If the gradient decreases by at least a factor of $c_2$, we accept the step (see the following diagram).</p>
<p><img src="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/line_search_accept.svg" alt="An acceptable step" /></p>
<p>If we are decreasing sufficiently, but the magnitude of the projected gradient isn't (the gray region in the previous plots), we are either undershooting the optimal step, in which case we should increase the step size and run the loop again (Step 4) or we are overshooting, in which case we should run <code>zoom</code> between the current step and the previous one. How do we tell? Well, if we overshoot, the gradient on the next step will tell us to move in the opposite direction, but if we undershoot, we should still be moving in the same direction. This is what the if-statement of Step 3. checks for.</p>
<p><img src="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/line_search_armijo.svg" alt="A step that would result in the final condition being checked" /></p>
<p>In the above plot, both points meet the Armijo condition, but they fail to meet the strong Wolfe condition. This means they make it to Step 3 in our line search algorithm. For the left-most point, the gradient points in the $-x$ direction while the step was in the $+x$ direction, so the condition at Step 3 is not satisfied, and we increase our step size (hopefully landing in the green region). For the right-most point, the gradient now points in the $+x$ direction, so Step 3 is satisfied and we again <code>zoom</code> between this step size and the previous. Note that the arguments to <code>zoom</code> are switched here. In the definition of the <code>zoom</code> algorithm, we will refer to the first argument as $\alpha_{\text{lo}}$ and the second as $\alpha_{\text{hi}}$. However, since $\alpha_i$ is strictly increasing in Algorithm 3.5, we shouldn't think of one of these values as larger than the other, but rather that the function evaluations at these points are lower or higher. Here, $\alpha_\text{lo}$ will always refer to a step length which satisfied the Armijo condition, which means that the function value with this step length is the lower of the two. $\alpha_\text{hi}$ will be the previous step if the current one is the first to satisfy the Armijo condition (Step 2.3) or it will be the current step if the previous step gave a smaller function evaluation (Step 2.1). In either case, we know that the optimal step length is in the given range.</p>
<h4 id="algorithm-3-6-zoom">Algorithm 3.6 (<code>zoom</code>)</h4>
<ol>
<li>loop
<ol>
<li>
<p>Choose $\alpha_j$ between $\alpha_{\text{lo}}$ and $\alpha_{\text{hi}}$ (it's possible for $\alpha_\text{lo} &gt; \alpha_\text{hi}$).</p>
</li>
<li>
<p><code>if</code></p>
<p>$f(\vec{x} + \alpha_j \vec{p}) &gt; f(\vec{x}) + c_1\alpha_j\left(\vec{p}\cdot\vec{g}(\vec{x})\right)$ (not Armijo)</p>
<p><code>or</code></p>
<p>$f(\vec{x} + \alpha_j \vec{p}) \geq f(\vec{x} + \alpha_{\text{lo}}\vec{p})$ (the function value has not decreased relative to $\alpha_{\text{lo}}$)</p>
<p><code>then</code> $\alpha_\text{hi} \gets \alpha_j$</p>
<p><code>else</code></p>
<ol>
<li>
<p><code>if</code></p>
<p>$\left|\vec{p}\cdot\vec{g}(\vec{x} + \alpha_j\vec{p})\right| \leq c_2\left|\vec{p}\cdot\vec{g}(\vec{x})\right|$</p>
<p><code>then</code> <code>return</code> $\alpha_j$</p>
</li>
<li>
<p><code>if</code></p>
<p>$\vec{p}\cdot\vec{g}(\vec{x} + \alpha_j\vec{p}) (\alpha_\text{hi} - \alpha_\text{lo}) \geq 0$</p>
<p><code>then</code> $\alpha_\text{hi} \gets \alpha_\text{lo}$</p>
</li>
<li>
<p>$\alpha_\text{lo} \gets \alpha_j$</p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>There are only a few possible outcomes of this loop. The "middle" outcome is to return $\alpha_j$ if it satisfies the Strong Wolfe and Armijo conditions. We check first for Armijo (remember, this is generally less restrictive), and if it's not satisfied, or if the evaluation is worse than $\alpha_{\text{lo}}$, we move $\alpha_{\text{hi}}$ to $\alpha_j$. Remember, the subscripts represent the relative value of the function evaluated at that step, and we know that <a href="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-1/#algorithm-3-5">Algorithm 3.5</a> will guarantee that the two steps given will surround the "green" region of optimal step size. If Armijo is satisfied but Wolfe is not, we will always move $\alpha_{\text{lo}}$ up to $\alpha_j$, but if the condition in 2.2 is met, this implies that either the order of $\alpha_{\text{hi}}$ and $\alpha_{\text{lo}}$ is opposite what we think it should be (because in reality these functions are not always smooth minima like the previous diagrams) or the step $\alpha_j$ no longer goes in the direction of steepest descent. In either case, we then need move our $\alpha_{\text{hi}}$ endpoint to $\alpha_{\text{lo}}$ first. I'd recommend drawing out several minima scenarios to get a handle on this algorithm, but eventually it will start to make some sense.</p>
<p>Together, these algorithms constitute a line search which should result in a step that satisfies Strong Wolfe curvature conditions. This is needed to get optimal convergence from BFGS-like algorithms, but in practice it's not always efficient to run either algorithm in a (possibly infinite) loop, so I add a maximum number of loops to both algorithms. From my own testing, most problems will have no issue converging within a maximum of <code>100</code> iterations for each algorithm. That being said, here's my implementation of the line search:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub struct </span><span>StrongWolfeLineSearch&lt;T&gt; {
</span><span>    </span><span style="color:#bf616a;">max_iters</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#bf616a;">max_zoom</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#bf616a;">c1</span><span>: T,
</span><span>    </span><span style="color:#bf616a;">c2</span><span>: T,
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl</span><span>&lt;T&gt; Default </span><span style="color:#b48ead;">for </span><span>StrongWolfeLineSearch&lt;T&gt;
</span><span style="color:#b48ead;">where
</span><span>    T: Float,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">default</span><span>() -&gt; </span><span style="color:#b48ead;">Self </span><span>{
</span><span>        </span><span style="color:#b48ead;">Self </span><span>{
</span><span>            max_iters: </span><span style="color:#d08770;">100</span><span>,
</span><span>            max_zoom: </span><span style="color:#d08770;">100</span><span>,
</span><span>            c1: convert!(1e-</span><span style="color:#d08770;">4</span><span>, T),
</span><span>            c2: convert!(</span><span style="color:#d08770;">0.9</span><span>, T),
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl</span><span>&lt;T&gt; StrongWolfeLineSearch&lt;T&gt;
</span><span style="color:#b48ead;">where
</span><span>    T: Float + RealField,
</span><span>{
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">f_eval</span><span>&lt;U, E&gt;(
</span><span>        &amp;</span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">x</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>        </span><span style="color:#bf616a;">status</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Status&lt;T&gt;,
</span><span>    ) -&gt; Result&lt;T, E&gt; {
</span><span>        status.</span><span style="color:#96b5b4;">inc_n_f_evals</span><span>();
</span><span>        func.</span><span style="color:#96b5b4;">evaluate</span><span>(x.</span><span style="color:#96b5b4;">as_slice</span><span>(), user_data)
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">g_eval</span><span>&lt;U, E&gt;(
</span><span>        &amp;</span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">x</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>        </span><span style="color:#bf616a;">status</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Status&lt;T&gt;,
</span><span>    ) -&gt; Result&lt;DVector&lt;T&gt;, E&gt; {
</span><span>        status.</span><span style="color:#96b5b4;">inc_n_g_evals</span><span>();
</span><span>        func.</span><span style="color:#96b5b4;">gradient</span><span>(x.</span><span style="color:#96b5b4;">as_slice</span><span>(), user_data).</span><span style="color:#96b5b4;">map</span><span>(DVector::from)
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#65737e;">// Algorithm 3.6
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">zoom</span><span>&lt;U, E&gt;(
</span><span>        &amp;</span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">x0</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>        </span><span style="color:#bf616a;">f0</span><span>: T,
</span><span>        </span><span style="color:#bf616a;">g0</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">p</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">alpha_lo</span><span>: T,
</span><span>        </span><span style="color:#bf616a;">alpha_hi</span><span>: T,
</span><span>        </span><span style="color:#bf616a;">status</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Status&lt;T&gt;,
</span><span>    ) -&gt; Result&lt;(</span><span style="color:#b48ead;">bool</span><span>, T, T, DVector&lt;T&gt;), E&gt; {
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> alpha_lo = alpha_lo;
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> alpha_hi = alpha_hi;
</span><span>        </span><span style="color:#b48ead;">let</span><span> dphi0 = g0.</span><span style="color:#96b5b4;">dot</span><span>(p);
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> i = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#b48ead;">loop </span><span>{
</span><span>            </span><span style="color:#b48ead;">let</span><span> alpha_i = (alpha_lo + alpha_hi) / convert!(</span><span style="color:#d08770;">2</span><span>, T);
</span><span>            </span><span style="color:#b48ead;">let</span><span> x = x0 + p.</span><span style="color:#96b5b4;">scale</span><span>(alpha_i);
</span><span>            </span><span style="color:#b48ead;">let</span><span> f_i = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">f_eval</span><span>(func, &amp;x, bounds, user_data, status)?;
</span><span>            </span><span style="color:#b48ead;">let</span><span> x_lo = x0 + p.</span><span style="color:#96b5b4;">scale</span><span>(alpha_lo);
</span><span>            </span><span style="color:#b48ead;">let</span><span> f_lo = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">f_eval</span><span>(func, &amp;x_lo, bounds, user_data, status)?;
</span><span>            </span><span style="color:#b48ead;">let</span><span> valid = </span><span style="color:#b48ead;">if </span><span>(f_i &gt; f0 + </span><span style="color:#bf616a;">self</span><span>.c1 * alpha_i * dphi0) || (f_i &gt;= f_lo) {
</span><span>                alpha_hi = alpha_i;
</span><span>                </span><span style="color:#d08770;">false
</span><span>            } </span><span style="color:#b48ead;">else </span><span>{
</span><span>                </span><span style="color:#b48ead;">let</span><span> g_i = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">g_eval</span><span>(func, &amp;x, bounds, user_data, status)?;
</span><span>                </span><span style="color:#b48ead;">let</span><span> dphi = g_i.</span><span style="color:#96b5b4;">dot</span><span>(p);
</span><span>                </span><span style="color:#b48ead;">if </span><span>Float::abs(dphi) &lt;= -</span><span style="color:#bf616a;">self</span><span>.c2 * dphi0 {
</span><span>                    </span><span style="color:#b48ead;">return </span><span>Ok((</span><span style="color:#d08770;">true</span><span>, alpha_i, f_i, g_i));
</span><span>                }
</span><span>                </span><span style="color:#b48ead;">if</span><span> dphi * (alpha_hi - alpha_lo) &gt;= T::zero() {
</span><span>                    alpha_hi = alpha_lo;
</span><span>                }
</span><span>                alpha_lo = alpha_i;
</span><span>                </span><span style="color:#d08770;">true
</span><span>            };
</span><span>            i += </span><span style="color:#d08770;">1</span><span>;
</span><span>            </span><span style="color:#b48ead;">if</span><span> i &gt; </span><span style="color:#bf616a;">self</span><span>.max_zoom {
</span><span>                </span><span style="color:#b48ead;">let</span><span> g_i = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">g_eval</span><span>(func, &amp;x, bounds, user_data, status)?;
</span><span>                </span><span style="color:#b48ead;">return </span><span>Ok((valid, alpha_i, f_i, g_i));
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl</span><span>&lt;T, U, E&gt; LineSearch&lt;T, U, E&gt; </span><span style="color:#b48ead;">for </span><span>StrongWolfeLineSearch&lt;T&gt;
</span><span style="color:#b48ead;">where
</span><span>    T: Float + FromPrimitive + Debug + RealField + </span><span style="color:#b48ead;">&#39;static</span><span>,
</span><span>{
</span><span>    </span><span style="color:#65737e;">// Algorithm 3.5
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">search</span><span>(
</span><span>        &amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>,
</span><span>        </span><span style="color:#bf616a;">x0</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">p</span><span>: &amp;DVector&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">max_step</span><span>: Option&lt;T&gt;,
</span><span>        </span><span style="color:#bf616a;">func</span><span>: &amp;dyn Function&lt;T, U, E&gt;,
</span><span>        </span><span style="color:#bf616a;">bounds</span><span>: Option&lt;&amp;Vec&lt;Bound&lt;T&gt;&gt;&gt;,
</span><span>        </span><span style="color:#bf616a;">user_data</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> U,
</span><span>        </span><span style="color:#bf616a;">status</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Status&lt;T&gt;,
</span><span>    ) -&gt; Result&lt;(</span><span style="color:#b48ead;">bool</span><span>, T, T, DVector&lt;T&gt;), E&gt; {
</span><span>        </span><span style="color:#b48ead;">let</span><span> f0 = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">f_eval</span><span>(func, x0, bounds, user_data, status)?;
</span><span>        </span><span style="color:#b48ead;">let</span><span> g0 = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">g_eval</span><span>(func, x0, bounds, user_data, status)?;
</span><span>        </span><span style="color:#b48ead;">let</span><span> alpha_max = max_step.</span><span style="color:#96b5b4;">map_or_else</span><span>(T::one, |</span><span style="color:#bf616a;">alpha_max</span><span>| alpha_max);
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> alpha_im1 = T::zero();
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> alpha_i = T::one();
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> f_im1 = f0;
</span><span>        </span><span style="color:#b48ead;">let</span><span> dphi0 = g0.</span><span style="color:#96b5b4;">dot</span><span>(p);
</span><span>        </span><span style="color:#b48ead;">let mut</span><span> i = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#b48ead;">loop </span><span>{
</span><span>            </span><span style="color:#b48ead;">let</span><span> x = x0 + p.</span><span style="color:#96b5b4;">scale</span><span>(alpha_i);
</span><span>            </span><span style="color:#b48ead;">let</span><span> f_i = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">f_eval</span><span>(func, &amp;x, bounds, user_data, status)?;
</span><span>            </span><span style="color:#b48ead;">if </span><span>(f_i &gt; f0 + </span><span style="color:#bf616a;">self</span><span>.c1 * dphi0) || (i &gt; </span><span style="color:#d08770;">1 </span><span>&amp;&amp; f_i &gt;= f_im1) {
</span><span>                </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">zoom</span><span>(
</span><span>                    func, x0, bounds, user_data, f0, &amp;g0, p, alpha_im1, alpha_i, status,
</span><span>                );
</span><span>            }
</span><span>            </span><span style="color:#b48ead;">let</span><span> g_i = </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">g_eval</span><span>(func, &amp;x, bounds, user_data, status)?;
</span><span>            </span><span style="color:#b48ead;">let</span><span> dphi = g_i.</span><span style="color:#96b5b4;">dot</span><span>(p);
</span><span>            </span><span style="color:#b48ead;">if </span><span>Float::abs(dphi) &lt;= </span><span style="color:#bf616a;">self</span><span>.c2 * Float::abs(dphi0) {
</span><span>                </span><span style="color:#b48ead;">return </span><span>Ok((</span><span style="color:#d08770;">true</span><span>, alpha_i, f_i, g_i));
</span><span>            }
</span><span>            </span><span style="color:#b48ead;">if</span><span> dphi &gt;= T::zero() {
</span><span>                </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#96b5b4;">zoom</span><span>(
</span><span>                    func, x0, bounds, user_data, f0, &amp;g0, p, alpha_i, alpha_im1, status,
</span><span>                );
</span><span>            }
</span><span>            alpha_im1 = alpha_i;
</span><span>            f_im1 = f_i;
</span><span>            alpha_i += convert!(</span><span style="color:#d08770;">0.8</span><span>, T) * (alpha_max - alpha_i);
</span><span>            i += </span><span style="color:#d08770;">1</span><span>;
</span><span>            </span><span style="color:#b48ead;">if</span><span> i &gt; </span><span style="color:#bf616a;">self</span><span>.max_iters {
</span><span>                </span><span style="color:#b48ead;">return </span><span>Ok((</span><span style="color:#d08770;">false</span><span>, alpha_i, f_i, g_i));
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>The full implementation (with a nicer API and some other features I'm not going to mention in these blog posts) can be found <a href="https://github.com/denehoffman/ganesh/blob/604a8ebd47c519fe07104439e87e22b2425e9f62/src/algorithms/line_search.rs">here</a>. In the <a href="https://denehoffman.com/blog/the-bfgs-algorithm-family-in-rust-part-2/">next post</a>, I will describe the first of the BFGS family of algorithms, the standard BFGS algorithm (no bounds, no limited-memory optimizations).</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>In the full code, there are additional clauses for updating outside <code>Observer</code>s, which can monitor the <code>Algorithm</code> at each step.</p>
</div>


<p class="tags-data">
  
</p>

      </main>
      <footer>
          <hr>
<div id="footer-container">
  
  <div>
    <p>Theme and color theme licensed under <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Licence_MIT">MIT</a>.<br>
      Built with <a target="_blank" rel="noopener noreferrer" href="https://www.getzola.org">Zola</a> using <a target="_blank" rel="noopener noreferrer" href="https://github.com/Speyll/anemone">anemone</a> theme, <a target="_blank" rel="noopener noreferrer" href="https://speyll.github.io/suCSS/">suCSS</a> framework &amp; <a target="_blank" rel="noopener noreferrer" href="https://github.com/Speyll/veqev">veqev</a>.<br>
    </p>

  </div>
  
</div>

      </footer>
</body>
</html>